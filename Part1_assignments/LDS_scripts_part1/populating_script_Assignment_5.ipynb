{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyodbc\n",
    "# # import pyodbc\n",
    "# # import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Database connection details\n",
    "SERVER = 'lds.di.unipi.it'      \n",
    "DATABASE = 'Group_ID_12_DB'    \n",
    "USERNAME = 'Group_ID_12'       \n",
    "PASSWORD = '04AIXZEG'          \n",
    "# Connection string for SQL Server\n",
    "CONN_STRING = f'DRIVER={{SQL Server}};SERVER={SERVER};DATABASE={DATABASE};UID={USERNAME};PWD={PASSWORD}'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # new block : get right string for table location\n",
    "\n",
    "# prefix_string = 'MVSalvatore'\n",
    "# string_SSMS = prefix_string + \".\" + DATABASE + \" - \" + USERNAME + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    \"\"\"Establish a connection to the SQL Server database.\"\"\"\n",
    "    try:\n",
    "        connection = pyodbc.connect(CONN_STRING)\n",
    "        print(\"Connected to the database.\")\n",
    "        return connection\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_table(connection, file_path, table_name, columns, batch_size = 1000): #batch add v2\n",
    "    \"\"\"\n",
    "    Load data from a CSV file into a SQL Server table.\n",
    "    :param connection: Database connection object\n",
    "    :param file_path: Path to the CSV file\n",
    "    :param table_name: Target table name in SQL Server\n",
    "    :param columns: List of column names in the target table\n",
    "    :param batch_size: Number of rows to process per batch\n",
    "    :return: Success or failure message\n",
    "    \"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    success = True # modified v2\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            next(csv_reader)  # Skip header row\n",
    "            rows = list(csv_reader) # v2\n",
    "            total_batches = math.ceil(len(rows) / batch_size) # v2 \n",
    "            print(f\"Processing {len(rows)} rows from {file_path} in {total_batches} batches.\") # v2\n",
    "\n",
    "            connection.autocommit = False  # Start a transaction v2\n",
    "            for batch_num in range(total_batches): #v2\n",
    "                start_idx = batch_num * batch_size #v2\n",
    "                end_idx = min(start_idx + batch_size, len(rows)) #v2\n",
    "                batch = rows[start_idx:end_idx] # v2\n",
    "\n",
    "                placeholders = ', '.join(['?'] * len(rows[0]))\n",
    "                sql_query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "                cursor.executemany(sql_query, batch)\n",
    "\n",
    "                print(f\"Batch {batch_num + 1}/{total_batches} loaded for {file_path}.\")\n",
    "\n",
    "            connection.commit()\n",
    "            print(f\"Data loaded into table {table_name} successfully.\")\n",
    "    except Exception as e:\n",
    "        connection.rollback()  # Roll back all changes for this file #v2\n",
    "        print(f\"Error loading file {file_path} into table {table_name}: {e}\") #v2\n",
    "        success = False #v2\n",
    "\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        return success #v2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database.\n",
      "Loading data from GeographyDimension.csv into GeographyDimension...\n",
      "Processing 274 rows from GeographyDimension.csv in 1 batches.\n",
      "Batch 1/1 loaded for GeographyDimension.csv.\n",
      "Data loaded into table GeographyDimension successfully.\n",
      "Database population complete.\n",
      "\n",
      "Summary of operations:\n",
      "Successful file loads:\n",
      " - GeographyDimension.csv\n",
      "Failed file loads:\n"
     ]
    }
   ],
   "source": [
    "# test just 1 table : full fact table at once\n",
    "\n",
    "def main():\n",
    "    # Establish connection to the database\n",
    "    connection = connect_to_db()\n",
    "    if not connection:\n",
    "        return\n",
    "\n",
    "    # Define mappings of CSV files to their respective tables and columns\n",
    "    file_table_mapping = {\n",
    "        'FactTable.csv': ('S_ClaimFactTable', ['crash_id', 'cause_id', 'person_id', 'vehicle_id', 'location_id', 'date_id', 'damage_category', 'damage']),\n",
    "        'VehicleDimension.csv': ('S_VehicleDimension', ['vehicle_id', 'crash_id', 'vehicle_type', 'manufacturer', 'model', 'registration_state']),\n",
    "        'CauseDimension.csv': ('S_CauseDimension', ['cause_id', 'primary_cause', 'secondary_cause', 'road_condition', 'lighting_condition', 'weather_condition', 'speed_limit', 'traffic_control_device', 'device_condition', 'alignment', 'road_defect']),\n",
    "        'PersonDimension.csv': ('S_PersonDimension', ['person_id', 'age', 'gender', 'role_in_crash', 'injury_severity', 'is_under_21']),\n",
    "        'GeographyDimension.csv': ('S_GeographyDimension', ['location_id', 'beat_id', 'street_name', 'street_number', 'area_risk_level']),\n",
    "        'DateDimension.csv': ('S_DateDimension', ['date_id', 'month', 'year', 'quarter', 'day_of_week', 'week_number', 'is_weekend', 'is_holiday']),\n",
    "        'CrashDimension.csv': ('S_CrashDimension', ['crash_id', 'crash_date', 'crash_time', 'num_units', 'crash_severity_category']) \n",
    "    }\n",
    "    # Track success and failure v2\n",
    "    successful_files = []\n",
    "    failed_files = []\n",
    "\n",
    "    # Load each CSV file into its respective table\n",
    "    for file_path, (table_name, columns) in file_table_mapping.items():\n",
    "        print(f\"Loading data from {file_path} into {table_name}...\")\n",
    "        success = load_csv_to_table(connection, file_path, table_name, columns, batch_size=1000) #v2\n",
    "        if success: #v2\n",
    "            successful_files.append(file_path) #v2\n",
    "        else: #v2\n",
    "            failed_files.append(file_path) #v2\n",
    "\n",
    "    # Close the database connection\n",
    "    connection.close()\n",
    "    print(\"Database population complete.\")\n",
    "    \n",
    "    # Printing summary\n",
    "    print(\"\\nSummary of operations:\")\n",
    "    print(\"Successful file loads:\")\n",
    "    for file in successful_files:\n",
    "        print(f\" - {file}\")\n",
    "    print(\"Failed file loads:\")\n",
    "    for file in failed_files:\n",
    "        print(f\" - {file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
